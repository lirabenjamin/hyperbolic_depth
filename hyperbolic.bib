@article{ainslie1974,
  title = {Impulse Control in Pigeons},
  author = {Ainslie, G. W.},
  year = {1974},
  month = may,
  journal = {Journal of the Experimental Analysis of Behavior},
  volume = {21},
  number = {3},
  pages = {485--489},
  issn = {0022-5002},
  doi = {10.1901/jeab.1974.21-485},
  urldate = {2023-10-12},
  abstract = {Pigeons were given a small, immediate food reinforcement for pecking a key, and a larger, delayed reinforcement for not pecking this key. Most subjects pecked the key on more than 95\% of trials. However, when pecking a differently colored key at an earlier time prevented this option from becoming available, three of 10 subjects consistently pecked it, thereby forcing themselves to wait for the larger reward. They did not peck the earlier key when it did not prevent this option. This is an experimental example of psychological impulse and a learnable device to control it. Although only a minority of the subjects learned it, the fact that such learning is possible at all argues for a theory of delayed reward that can predict change of preference as a function of elapsing time.},
  pmcid = {PMC1333221},
  pmid = {16811760},
  file = {/Users/blira/Zotero/storage/NQ4Y4V38/Ainslie - 1974 - Impulse control in pigeons.pdf}
}

@article{ali2023,
  title = {Non-Exponential {{Reward Discounting}} in {{Reinforcement Learning}}},
  author = {Ali, Raja Farrukh},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {13},
  pages = {16111--16112},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i13.26916},
  urldate = {2023-11-15},
  abstract = {Reinforcement learning methods typically discount future rewards using an exponential scheme to achieve theoretical convergence guarantees. Studies from neuroscience, psychology, and economics suggest that human and animal behavior is better captured by the hyperbolic discounting model. Hyperbolic discounting has recently been studied in deep reinforcement learning and has shown promising results. However, this area of research is seemingly understudied, with most extant and continuing research using the standard exponential discounting formulation. My dissertation examines the effects of non-exponential discounting functions (such as hyperbolic) on an agent's learning and aims to investigate their impact on multi-agent systems and generalization tasks. A key objective of this study is to link the discounting rate to an agent's approximation of the underlying hazard rate of its environment through survival analysis.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/BSP55UHS/Ali - 2023 - Non-exponential Reward Discounting in Reinforcemen.pdf}
}

@article{buehner2003,
  title = {From {{Covariation}} to {{Causation}}: {{A Test}} of the {{Assumption}} of {{Causal Power}}.},
  shorttitle = {From {{Covariation}} to {{Causation}}},
  author = {Buehner, Marc J. and Cheng, Patricia W. and Clifford, Deborah},
  year = {2003},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {29},
  number = {6},
  pages = {1119--1140},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/0278-7393.29.6.1119},
  urldate = {2023-10-16},
  langid = {english},
  file = {/Users/blira/Zotero/storage/PSETK9CT/Buehner et al. - 2003 - From Covariation to Causation A Test of the Assum.pdf}
}

@article{dasgupta2005,
  title = {Uncertainty and {{Hyperbolic Discounting}}},
  author = {Dasgupta, Partha and Maskin, Eric},
  year = {2005},
  journal = {The American Economic Review},
  volume = {95},
  number = {4},
  eprint = {4132716},
  eprinttype = {jstor},
  pages = {1290--1299},
  publisher = {{American Economic Association}},
  issn = {0002-8282},
  urldate = {2023-11-15}
}

@article{farmer2009,
  title = {Hyperbolic {{Discounting}} Is {{Rational}}: {{Valuing}} the {{Far Future}} with {{Uncertain Discount Rates}}},
  shorttitle = {Hyperbolic {{Discounting}} Is {{Rational}}},
  author = {Farmer, J. Doyne and Geanakoplos, John},
  year = {2009},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.1448811},
  urldate = {2023-10-10},
  abstract = {Conventional economics supposes that agents value the present vs. the future using an exponential discounting function. In contrast, experiments with animals and humans suggest that agents are better described as hyperbolic discounters, whose discount function decays much more slowly at large times, as a power law. This is generally regarded as being time inconsistent or irrational. We show that when agents cannot be sure of their own future one-period discount rates, then hyperbolic discounting can become rational and exponential discounting irrational. This has important implications for environmental economics, as it implies a much larger weight for the far future.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/PRDPGQH4/Farmer and Geanakoplos - 2009 - Hyperbolic Discounting is Rational Valuing the Fa.pdf}
}

@misc{fedus2019,
  title = {Hyperbolic {{Discounting}} and {{Learning}} over {{Multiple Horizons}}},
  author = {Fedus, William and Gelada, Carles and Bengio, Yoshua and Bellemare, Marc G. and Larochelle, Hugo},
  year = {2019},
  month = feb,
  number = {arXiv:1902.06865},
  eprint = {1902.06865},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-10-16},
  abstract = {Reinforcement learning (RL) typically defines a discount factor as part of the Markov Decision Process. The discount factor values future rewards by an exponential scheme that leads to theoretical convergence guarantees of the Bellman equation. However, evidence from psychology, economics and neuroscience suggests that humans and animals instead have hyperbolic time-preferences. In this work we revisit the fundamentals of discounting in RL and bridge this disconnect by implementing an RL agent that acts via hyperbolic discounting. We demonstrate that a simple approach approximates hyperbolic discount functions while still using familiar temporal-difference learning techniques in RL. Additionally, and independent of hyperbolic discounting, we make a surprising discovery that simultaneously learning value functions over multiple time-horizons is an effective auxiliary task which often improves over a strong value-based RL agent, Rainbow.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/blira/Zotero/storage/FPMASGLW/Fedus et al. - 2019 - Hyperbolic Discounting and Learning over Multiple .pdf;/Users/blira/Zotero/storage/CWMWL3F6/1902.html}
}

@article{green1996,
  title = {Exponential {{Versus Hyperbolic Discounting}} of {{Delayed Outcomes}}: {{Risk}} and {{Waiting Time}}},
  shorttitle = {Exponential {{Versus Hyperbolic Discounting}} of {{Delayed Outcomes}}},
  author = {Green, Leonard and Myerson, Joel},
  year = {1996},
  month = sep,
  journal = {American Zoologist},
  volume = {36},
  number = {4},
  pages = {496--505},
  issn = {0003-1569},
  doi = {10.1093/icb/36.4.496},
  urldate = {2023-10-16},
  langid = {english},
  file = {/Users/blira/Zotero/storage/LNM98PB9/Green and Myerson - 1996 - Exponential Versus Hyperbolic Discounting of Delay.pdf}
}

@article{greville2010,
  title = {Temporal Predictability Facilitates Causal Learning.},
  author = {Greville, W. James and Buehner, Marc J.},
  year = {2010},
  journal = {Journal of Experimental Psychology: General},
  volume = {139},
  number = {4},
  pages = {756--771},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/a0020976},
  urldate = {2023-10-16},
  abstract = {Temporal predictability refers to the regularity or consistency of the time interval separating events. When encountering repeated instances of causes and effects, we also experience multiple cause\textendash{} effect temporal intervals. Where this interval is constant it becomes possible to predict when the effect will follow from the cause. In contrast, interval variability entails unpredictability. Three experiments investigated the extent to which temporal predictability contributes to the inductive processes of human causal learning. The authors demonstrated that (a) causal relations with fixed temporal intervals are consistently judged as stronger than those with variable temporal intervals, (b) that causal judgments decline as a function of temporal uncertainty, and (c) that this effect remains undiminished with increased learning time. The results therefore clearly indicate that temporal predictability facilitates causal discovery. The authors considered the implications of their findings for various theoretical perspectives, including associative learning theory, the attribution shift hypothesis, and causal structure models.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/2JQ4U8PK/Greville and Buehner - 2010 - Temporal predictability facilitates causal learnin.pdf}
}

@article{greville2012,
  title = {Assessing {{Evidence}} for a {{Common Function}} of {{Delay}} in {{Causal Learning}} and {{Reward Discounting}}},
  author = {Greville, W. James and Buehner, Marc J.},
  year = {2012},
  journal = {Frontiers in Psychology},
  volume = {3},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2012.00460},
  urldate = {2023-10-16},
  abstract = {Time occupies a central role in both the induction of causal relationships and determining the subjective value of rewards. Delays devalue rewards and also impair learning of relationships between events. The mathematical relation between the time until a delayed reward and its present value has been characterized as a hyperbola-like function, and increasing delays of reinforcement tend to elicit judgments or response rates that similarly show a negatively accelerated decay pattern. Furthermore, neurological research implicates both the hippocampus and prefrontal cortex in both these processes. Since both processes are broadly concerned with the concepts of reward, value, and time, involve a similar functional form, and have been identified as involving the same specific brain regions, it seems tempting to assume that the two processes are underpinned by the same cognitive or neural mechanisms. We set out to determine experimentally whether a common cognitive mechanism underlies these processes, by contrasting individual performances on causal judgment and delay discounting tasks. Results from each task corresponded with previous findings in the literature, but no relation was found between the two tasks. The task was replicated and extended by including two further measures, the Barrett Impulsiveness Scale (BIS), and a causal attribution task. Performance on this latter task was correlated with results on the causal judgment task, and also with the non-planning component of the BIS, but the results from the delay discounting task was not correlated with either causal learning task nor the BIS. Implications for current theories of learning are considered.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/69FQCXHE/Greville and Buehner - 2012 - Assessing Evidence for a Common Function of Delay .pdf}
}

@article{hoerl2020,
  title = {Temporal {{Binding}}, {{Causation}}, and {{Agency}}: {{Developing}} a {{New Theoretical Framework}}},
  shorttitle = {Temporal {{Binding}}, {{Causation}}, and {{Agency}}},
  author = {Hoerl, Christoph and Lorimer, Sara and McCormack, Teresa and Lagnado, David A. and Blakey, Emma and Tecwyn, Emma C. and Buehner, Marc J.},
  year = {2020},
  month = may,
  journal = {Cognitive Science},
  volume = {44},
  number = {5},
  pages = {e12843},
  issn = {0364-0213, 1551-6709},
  doi = {10.1111/cogs.12843},
  urldate = {2023-10-16},
  abstract = {Abstract             In temporal binding, the temporal interval between one event and another, occurring some time later, is subjectively compressed. We discuss two ways in which temporal binding has been conceptualized. In studies showing temporal binding between a voluntary action and its causal consequences, such binding is typically interpreted as providing a measure of an implicit or pre-reflective ``sense of agency.'' However, temporal binding has also been observed in contexts not involving voluntary action, but only the passive observation of a cause\textendash effect sequence. In those contexts, it has been interpreted as a top-down effect on perception reflecting a belief in causality. These two views need not be in conflict with one another, if one thinks of them as concerning two separate mechanisms through which temporal binding can occur. In this paper, we explore an alternative possibility: that there is a unitary way of explaining temporal binding both within and outside the context of voluntary action as a top-down effect on perception reflecting a belief in causality. Any such explanation needs to account for ways in which agency, and factors connected with agency, has been shown to affect the strength of temporal binding. We show that principles of causal inference and causal selection already familiar from the literature on causal learning have the potential to explain why the strength of people's causal beliefs can be affected by the extent to which they are themselves actively involved in bringing about events, thus in turn affecting binding.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/9D94KGFL/Hoerl et al. - 2020 - Temporal Binding, Causation, and Agency Developin.pdf}
}

@article{laibson1997,
  title = {Golden {{Eggs}} and {{Hyperbolic Discounting}}*},
  author = {Laibson, David},
  year = {1997},
  month = may,
  journal = {The Quarterly Journal of Economics},
  volume = {112},
  number = {2},
  pages = {443--478},
  issn = {0033-5533},
  doi = {10.1162/003355397555253},
  urldate = {2023-10-12},
  abstract = {Hyperbolic discount functions induce dynamically inconsistent preferences, implying a motive for consumers to constrain their own future choices. This paper analyzes the decisions of a hyperbolic consumer who has access to an imperfect commitment technology: an illiquid asset whose sale must be initiated one period before the sale proceeds are received. The model predicts that consumption tracks income, and the model explains why consumers have asset-specific marginal propensities to consume. The model suggests that financial innovation may have caused the ongoing decline in U. S. savings rates, since financial innovation increases liquidity, eliminating commitment opportunities. Finally, the model implies that financial market innovation may reduce welfare by providing ``too much'' liquidity.},
  file = {/Users/blira/Zotero/storage/I5BGYLFS/Laibson - 1997 - Golden Eggs and Hyperbolic Discounting.pdf;/Users/blira/Zotero/storage/VQ8T3WYG/1870925.html}
}

@article{mcnamara1980,
  title = {The Application of Statistical Decision Theory to Animal Behaviour},
  author = {McNamara, John and Houston, Alasdair},
  year = {1980},
  month = aug,
  journal = {Journal of Theoretical Biology},
  volume = {85},
  number = {4},
  pages = {673--690},
  issn = {00225193},
  doi = {10.1016/0022-5193(80)90265-9},
  urldate = {2023-10-09},
  langid = {english},
  file = {/Users/blira/Zotero/storage/92LS7BCZ/McNamara and Houston - 1980 - The application of statistical decision theory to .pdf}
}

@article{nafi,
  title = {Hyperbolically {{Discounted Advantage Estimation}} for {{Generalization}} in {{Reinforcement Learning}}},
  author = {Nafi, Nasik Muhammad and Ali, Raja Farrukh and Hsu, William},
  abstract = {In reinforcement learning (RL), agents typically discount future rewards using an exponential scheme. However, studies have shown that humans and animals instead exhibit hyperbolic timepreferences and thus discount future rewards hyperbolically. In the quest for RL agents that generalize well to previously unseen scenarios, we study the effects of hyperbolic discounting on generalization tasks and present Hyperbolic Discounting for Generalization in Reinforcement Learning (HDGenRL). We propose a hyperbolic discounting-based advantage estimation method that makes the agent aware of and robust to the underlying uncertainty of survival and episode duration. On the challenging RL generalization benchmark Procgen, our proposed approach achieves up to 200\% performance improvement over the PPO baseline that uses classical exponential discounting. We also incorporate hyperbolic discounting into another generalization-specific approach (APDAC), and results indicate further improvement in APDAC's generalization ability. This denotes the effectiveness of our approach as a plug-in to any existing methods to aid generalization.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/ELJWS29D/Nafi et al. - Hyperbolically Discounted Advantage Estimation for.pdf}
}

@article{ostaszewski1996,
  title = {The Relation between Temperament and Rate of Temporal Discounting},
  author = {Ostaszewski, Pawel},
  year = {1996},
  month = sep,
  journal = {European Journal of Personality},
  volume = {10},
  number = {3},
  pages = {161--172},
  issn = {0890-2070},
  abstract = {Examined the relationship between several temperamental traits (sensation seeking, extraversion-introversion, and impulsivity) and rate of temporal discounting, that is the rate of decrease in the subjective value of a reward as the delay to its receipt increases. 67 university students made choices between hypothetical monetary rewards that could be obtained immediately or after a specified delay. Temporal discounting functions were calculated and differences in rate of discounting between different groups were evaluated. For all groups of participants, hyperbolic discounting functions described well the decreases in subjective value with delay. The rate of discounting was equivalent in high and low sensation seekers. However, both extraverts and high impulsive individuals showed higher temporal discounting rates than introverts and low impulsive individuals. (PsycINFO Database Record (c) 2006 APA )},
  keywords = {3120 Personality Traits \& Processes,Adult Attitudes,college,Extraversion,Impulsiveness,impulsivity,Introversion,Motivation,Poland,rate of temporal discounting of rewards,Rewards,Seeking,Sensation,sensation seeking \& extraversion \& introversion \&,students},
  file = {/Users/blira/Zotero/storage/DHLH3AB6/OstaszewskiPDF.pdf}
}

@article{ostaszewski2013,
  title = {Physical and Cognitive Effort Discounting of Hypothetical Monetary Rewards},
  author = {Ostaszewski, Pawe{\l} and B{\k{a}}bel, Przemys{\l}aw and Swebodzi{\'n}ski, Bart{\l}omiej},
  year = {2013},
  journal = {Japanese Psychological Research},
  volume = {55},
  number = {4},
  pages = {329--337},
  issn = {1468-5884},
  doi = {10.1111/jpr.12019},
  urldate = {2023-01-20},
  abstract = {Effort discounting refers to the decrease in the subjective value of a reward as the effort required to obtain the reward increases. The main aims of this study were to ascertain whether the amount of the reward affects the steepness of the effort discounting process for hypothetical monetary rewards, to identify whether this steepness depends on the type of effort that is required, and to determine whether the steepness of different types of effort covary at the individual level. Two types of effort were studied under hypothetical choice situations: physical effort and cognitive effort. Both physical and cognitive effort discounting were well described by the hyperbolic model. Large rewards were discounted less steeply than small rewards for both types of effort. This finding agrees with the results of prior studies which have found that larger rewards have greater motivational power. In addition, the steepness of physical effort discounting was positively correlated with the steepness of cognitive effort discounting, which suggests that the effort discounting process is a trait-like characteristic within an individual.},
  langid = {english},
  keywords = {cognitive effort,effort discounting,magnitude effect,physical effort},
  file = {/Users/blira/Zotero/storage/48HVYMMU/Ostaszewski et al. - 2013 - Physical and cognitive effort discounting of hypot.pdf;/Users/blira/Zotero/storage/LKZP3BQV/jpr.html}
}

@article{rachlin1972,
  title = {Commitment, {{Choice}} and {{Self-Control1}}},
  author = {Rachlin, Howard and Green, Leonard},
  year = {1972},
  journal = {Journal of the Experimental Analysis of Behavior},
  volume = {17},
  number = {1},
  pages = {15--22},
  issn = {1938-3711},
  doi = {10.1901/jeab.1972.17-15},
  urldate = {2023-11-15},
  abstract = {When offered a choice (Choice Y) between a small immediate reward (2-sec exposure to grain) and a large reward (4-sec exposure to grain) delayed by 4 sec, pigeons invariably preferred the small, immediate reward. However, when offered a choice (Choice X) between a delay of T seconds followed by Choice Y and a delay of T seconds followed by restriction to the large delayed reward only, the pigeon's choice depended on T. When T was small, the pigeons chose the alternative leading to Choice Y (and then chose the small, immediate reward). When T was large, the pigeons chose the alternative leading to the large delayed reward only. The reversal of preference as T increases is predicted by several recent models for choice between various amounts and delays of reward. The preference for the large delayed alternative with long durations of T parallels everyday instances of advance commitment to a given course of action. Such commitment may be seen as a prototype for self-control.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/KTTVBUKG/Rachlin and Green - 1972 - Commitment, Choice and Self-Control1.pdf;/Users/blira/Zotero/storage/DBP3GGG7/jeab.1972.html}
}

@article{rachlin1991,
  title = {Subjective {{Probability}} and {{Delay}}},
  author = {Rachlin, Howard and Raineri, Andres and Cross, David},
  year = {1991},
  journal = {Journal of the Experimental Analysis of Behavior},
  volume = {55},
  number = {2},
  pages = {233--244},
  issn = {1938-3711},
  doi = {10.1901/jeab.1991.55-233},
  urldate = {2023-11-15},
  abstract = {Human subjects indicated their preference between a hypothetical \textbackslash 1,000 reward available with various probabilities or delays and a certain reward of variable amount available immediately. The function relating the amount of the certain-immediate reward subjectively equivalent to the delayed \textbackslash 1,000 reward had the same general shape (hyperbolic) as the function found by Mazur (1987) to describe pigeons' delay discounting. The function relating the certain-immediate amount of money subjectively equivalent to the probabilistic \textbackslash 1,000 reward was also hyperbolic, provided that the stated probability was transformed to odds against winning. In a second experiment, when human subjects chose between a delayed \textbackslash 1,000 reward and a probabilistic \$1,000 reward, delay was proportional to the same odds-against transformation of the probability to which it was subjectively equivalent.},
  langid = {english},
  keywords = {choice,delay,discounting,humans,probability},
  file = {/Users/blira/Zotero/storage/HXLSCQET/Rachlin et al. - 1991 - Subjective Probability and Delay.pdf;/Users/blira/Zotero/storage/4DBCPYGM/jeab.1991.html}
}

@book{rachlin2004science,
  title = {The Science of Self-Control},
  author = {Rachlin, Howard},
  year = {2004},
  publisher = {{Harvard University Press}}
}

@article{rachlin2008,
  title = {Social Discounting and Delay Discounting},
  author = {Rachlin, Howard and Jones, Bryan A.},
  year = {2008},
  journal = {Journal of Behavioral Decision Making},
  volume = {21},
  number = {1},
  pages = {29--43},
  issn = {1099-0771},
  doi = {10.1002/bdm.567},
  abstract = {Social discounting was measured as the amount of money a participant was willing to forgo to give a fixed amount (usually \$75) to another person. In the first experiment, amount forgone was a hyperbolic function of the social distance between the giver and receiver. In the second experiment, degree of social discounting was an increasing function of reward magnitude whereas degree of delay discounting was a decreasing function of reward magnitude. In the third experiment, the shape of the function relating delayed rewards to equally valued immediate rewards for another person was predicted from individual delay and social discount functions. All in all, the studies show that the social discount function, like delay and probability discount functions, is hyperbolic in form. Copyright \textcopyright{} 2007 John Wiley \& Sons, Ltd.},
  keywords = {delay discounting,discounting,hyperbolic discounting,magnitude estimation,probability discounting,social discounting}
}

@article{sargisson2020,
  title = {Hyperbolic {{Discounting}} with {{Environmental Outcomes}} across {{Time}}, {{Space}}, and {{Probability}}},
  author = {Sargisson, Rebecca J. and Sch{\"o}ner, Benedikt V.},
  year = {2020},
  month = sep,
  journal = {The Psychological Record},
  volume = {70},
  number = {3},
  pages = {515--527},
  issn = {0033-2933, 2163-3452},
  doi = {10.1007/s40732-019-00368-z},
  urldate = {2023-11-15},
  abstract = {Environmental discounting is a potentially important research area for climate change mitigation. We aimed to replicate and extend earlier work on the discounting of a negative environmental outcome. We measured ratings of concern, and willingness to act to mitigate, an outcome involving air pollution that would hypothetically affect the garden and drinking water of the participants over psychological distance represented by temporal (1 month, 6 months, and 1, 3, 5, 10, and 80 years), spatial (5, 20, 50, 100, 1000, and 5000 km), and probabilistic (95\%, 90\%, 50\%, 30\%, 10\%, and 5\% likelihood) dimensions. For our data from 224 first-year psychology students, of four potential models (an exponential, simple hyperbolic, and two hyperboloid functions), the Rachlin hyperboloid was the best-fitting model describing ratings of concern and action across all three dimensions. Willingness to act was discounted more steeply than concern across all dimensions. There was little difference in discounting for outcomes described as human-caused rather than natural, except that willingness to act was discounted more steeply than concern for human-caused environmental outcomes compared to natural outcomes across spatial (and, less conclusively, temporal) distance. Presenting values of the three dimensions in random or progressive order had little effect on the results. Our results reflect the often-reported attitudebehavior gap whereby people maintain concern about a negative event over dimensions of psychological distance, but their willingness to act to mitigate the event is lower and more steeply discounted.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/UTJPSDLP/Sargisson and Schöner - 2020 - Hyperbolic Discounting with Environmental Outcomes.pdf}
}

@article{schultheis,
  title = {Reinforcement {{Learning}} with {{Non-Exponential Discounting}}},
  author = {Schultheis, Matthias and Rothkopf, Constantin A and Koeppl, Heinz},
  abstract = {Commonly in reinforcement learning (RL), rewards are discounted over time using an exponential function to model time preference, thereby bounding the expected long-term reward. In contrast, in economics and psychology, it has been shown that humans often adopt a hyperbolic discounting scheme, which is optimal when a specific task termination time distribution is assumed. In this work, we propose a theory for continuous-time model-based reinforcement learning generalized to arbitrary discount functions. This formulation covers the case in which there is a non-exponential random termination time. We derive a Hamilton\textendash Jacobi\textendash Bellman (HJB) equation characterizing the optimal policy and describe how it can be solved using a collocation method, which uses deep learning for function approximation. Further, we show how the inverse RL problem can be approached, in which one tries to recover properties of the discount function given decision data. We validate the applicability of our proposed approach on two simulated problems. Our approach opens the way for the analysis of human discounting in sequential decision-making tasks.},
  langid = {english},
  file = {/Users/blira/Zotero/storage/UAYMIAM7/Schultheis et al. - Reinforcement Learning with Non-Exponential Discou.pdf}
}

@article{sozou1998,
  title = {On Hyperbolic Discounting and Uncertain Hazard Rates},
  author = {Sozou, P. D.},
  year = {1998},
  month = oct,
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  volume = {265},
  number = {1409},
  pages = {2015--2020},
  issn = {0962-8452},
  doi = {10.1098/rspb.1998.0534},
  urldate = {2023-10-10},
  abstract = {The value of a future reward should be discounted where there is a risk that the reward will not be realized. If the risk manifests itself at a known, constant hazard rate, a risk-neutral recipient should discount the reward according to an exponential time-preference function. Experimental subjects, however, exhibit short-term time preferences that differ from the exponential in a manner consistent with a hazard rate that falls with increasing delay. It is shown here that this phenomenon can be explained by uncertainty in the underlying hazard. The time-preference function predicted by this analysis can be calculated by means of either (i) a direct superposition method, or (ii) Bayesian updating of the expected hazard rate. The observed hyperbolic time-preference function is consistent with an exponential prior distribution for the underlying hazard rate. Sensitivity of the predicted time-preference function to variation in the probability distribution of the underlying hazard rate is explored.},
  pmcid = {PMC1689473},
  pmid = {null},
  file = {/Users/blira/Zotero/storage/M9B5J22A/Sozou - 1998 - On hyperbolic discounting and uncertain hazard rat.pdf}
}

@article{story2014,
  title = {Does Temporal Discounting Explain Unhealthy Behavior? {{A}} Systematic Review and Reinforcement Learning Perspective},
  shorttitle = {Does Temporal Discounting Explain Unhealthy Behavior?},
  author = {Story, Giles and Vlaev, Ivo and Seymour, Ben and Darzi, Ara and Dolan, Ray},
  year = {2014},
  journal = {Frontiers in Behavioral Neuroscience},
  volume = {8},
  issn = {1662-5153},
  urldate = {2022-12-06},
  abstract = {The tendency to make unhealthy choices is hypothesized to be related to an individual's temporal discount rate, the theoretical rate at which they devalue delayed rewards. Furthermore, a particular form of temporal discounting, hyperbolic discounting, has been proposed to explain why unhealthy behavior can occur despite healthy intentions. We examine these two hypotheses in turn. We first systematically review studies which investigate whether discount rates can predict unhealthy behavior. These studies reveal that high discount rates for money (and in some instances food or drug rewards) are associated with several unhealthy behaviors and markers of health status, establishing discounting as a promising predictive measure. We secondly examine whether intention-incongruent unhealthy actions are consistent with hyperbolic discounting. We conclude that intention-incongruent actions are often triggered by environmental cues or changes in motivational state, whose effects are not parameterized by hyperbolic discounting. We propose a framework for understanding these state-based effects in terms of the interplay of two distinct reinforcement learning mechanisms: a ``model-based'' (or goal-directed) system and a ``model-free'' (or habitual) system. Under this framework, while discounting of delayed health may contribute to the initiation of unhealthy behavior, with repetition, many unhealthy behaviors become habitual; if health goals then change, habitual behavior can still arise in response to environmental cues. We propose that the burgeoning development of computational models of these processes will permit further identification of health decision-making phenotypes.},
  file = {/Users/blira/Zotero/storage/EQK8X7WV/Story et al. - 2014 - Does temporal discounting explain unhealthy behavi.pdf}
}

@book{sutton1998,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, R. S. and Barto, Andrew G.},
  year = {1998},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}}
}
